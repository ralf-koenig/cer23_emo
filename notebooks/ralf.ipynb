{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Text Classification for Emotions using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voraussetzungen\n",
    "\n",
    "* CUDA-fähige Grafikkarte mit 8 GB RAM - dieser Wert (ca. 7.3 GB, geprüft mit Linux-Befehl `nvidia-smi`) wird beim Training als VRAM-Auslastung erreicht mit der Batch size 8 für das Modell `bert-base-cased`\n",
    "* Damit bekommt man in dem Schritt etwa 3,4 it/seconds. Mit batch_size 10, was noch in den Speicher passt, würden es weniger werden.\n",
    "\n",
    "* Ausführungszeit: auf 20.000 Datensätzen => ca. 1:40 h:mm, also 1 h und 40 min\n",
    "* auf gesamter Trainingsdatenmenge von 58.000 Datensätzen dann etwa 4,5 Stunden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  7 23:35:49 CEST 2023\n"
     ]
    }
   ],
   "source": [
    "# Startzeitpunkt dieses Jupyter-Notebooks\n",
    "! date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abhängigkeiten installieren\n",
    "# ! pip install datasets huggingface_hub ipywidgets evaluate 'transformers[torch]' torch xformers plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# We need the sys package to load modules from another directory:\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from preprocessing.preprocessors import *\n",
    "\n",
    "import random # für random.sample\n",
    "import evaluate # für Evaluierung beim Training des Classifiers\n",
    "\n",
    "from datasets import Dataset # um damit Transformer-kompatible Datasets zu erzeugen, die vorher in Panda DataFrames gespeichert sind \n",
    "from sklearn.metrics import classification_report # ganz am Ende wird damit ein Bericht erzeugt, der die Klassifikation bewertet\n",
    "from transformers import AutoTokenizer # damit wird der Tokenizer zu einem Huggingface-Modell gebildet\n",
    "from transformers import DataCollatorWithPadding # damit werden gleich lange Input-Sequenzen erzeugt, die dann ins Transformer-Modell gehen, es wird also trunkiert und gepadded\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer  # für das Transfer Learning des angepassten Modells\n",
    "from transformers import pipeline # Inferenz-Pipeline zusammenbauen\n",
    "from tqdm import tqdm # Fortschritts-Monitoring\n",
    "\n",
    "# Grafiken erzeugen ähnlich zu ggplot in R\n",
    "# from plotnine import ggplot, aes, geom_tile, coord_flip, theme, geom_line, labs, element_text\n",
    "# from plotnine import scale_x_discrete, geom_vline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispieltexte komplett ansehen können\n",
    "pd.options.display.max_colwidth = None # default value is 50, max would be \"None\"\n",
    "pd.set_option('display.max_rows', 50) # default value is 10, max would be \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Falcon.</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Right? Considering it’s such an important document, I should know the damned thing backwards and forwards... thanks again for the help!</td>\n",
       "      <td>eespn2i</td>\n",
       "      <td>ImperialBoss</td>\n",
       "      <td>TrueReddit</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211219</th>\n",
       "      <td>Well, I'm glad you're out of all that now. How awful. The way they act, they make you think healthy boundaries are you being hostile.</td>\n",
       "      <td>ed89acy</td>\n",
       "      <td>pompompompi</td>\n",
       "      <td>raisedbynarcissists</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>Everyone likes [NAME].</td>\n",
       "      <td>ee6pagw</td>\n",
       "      <td>Senshado</td>\n",
       "      <td>heroesofthestorm</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>Well when you’ve imported about a gazillion of them I or your country it’s gets serious.</td>\n",
       "      <td>ef28nod</td>\n",
       "      <td>5inchloser</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>ee8hse1</td>\n",
       "      <td>springt1me</td>\n",
       "      <td>shittyfoodporn</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here, it's usually criticized horribly off base. It needs to grow some balls and actually enforce things.</td>\n",
       "      <td>edrhoxh</td>\n",
       "      <td>enamedata</td>\n",
       "      <td>medicine</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171820 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                        text  \\\n",
       "0                                                                                                                                            That game hurt.   \n",
       "2                                                                                                             You do right, if you don't care then fuck 'em!   \n",
       "3                                                                                                                                         Man I love reddit.   \n",
       "4                                                                                                       [NAME] was nowhere near them, he was by the Falcon.    \n",
       "5                    Right? Considering it’s such an important document, I should know the damned thing backwards and forwards... thanks again for the help!   \n",
       "...                                                                                                                                                      ...   \n",
       "211219                 Well, I'm glad you're out of all that now. How awful. The way they act, they make you think healthy boundaries are you being hostile.   \n",
       "211220                                                                                                                                Everyone likes [NAME].   \n",
       "211221                                                              Well when you’ve imported about a gazillion of them I or your country it’s gets serious.   \n",
       "211222                                                                                                                                    That looks amazing   \n",
       "211223  The FDA has plenty to criticize. But like here, it's usually criticized horribly off base. It needs to grow some balls and actually enforce things.    \n",
       "\n",
       "             id               author            subreddit  rater_id  \\\n",
       "0       eew5j0j                Brdd9                  nrl         1   \n",
       "2       ed2mah1             Labalool          confessions        37   \n",
       "3       eeibobj        MrsRobertshaw             facepalm        18   \n",
       "4       eda6yn6  American_Fascist713  starwarsspeculation         2   \n",
       "5       eespn2i         ImperialBoss           TrueReddit        61   \n",
       "...         ...                  ...                  ...       ...   \n",
       "211219  ed89acy          pompompompi  raisedbynarcissists         2   \n",
       "211220  ee6pagw             Senshado     heroesofthestorm        16   \n",
       "211221  ef28nod           5inchloser          nottheonion        15   \n",
       "211222  ee8hse1           springt1me       shittyfoodporn        70   \n",
       "211223  edrhoxh            enamedata             medicine         4   \n",
       "\n",
       "        admiration  amusement  anger  annoyance  approval  ...  love  \\\n",
       "0                0          0      0          0         0  ...     0   \n",
       "2                0          0      0          0         0  ...     0   \n",
       "3                0          0      0          0         0  ...     1   \n",
       "4                0          0      0          0         0  ...     0   \n",
       "5                0          0      0          0         0  ...     0   \n",
       "...            ...        ...    ...        ...       ...  ...   ...   \n",
       "211219           0          0      0          0         0  ...     0   \n",
       "211220           0          0      0          0         0  ...     1   \n",
       "211221           0          0      0          0         0  ...     0   \n",
       "211222           1          0      0          0         0  ...     0   \n",
       "211223           0          0      1          0         0  ...     0   \n",
       "\n",
       "        nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
       "0                 0         0      0            0       0        0        1   \n",
       "2                 0         0      0            0       0        0        0   \n",
       "3                 0         0      0            0       0        0        0   \n",
       "4                 0         0      0            0       0        0        0   \n",
       "5                 0         0      0            0       0        0        0   \n",
       "...             ...       ...    ...          ...     ...      ...      ...   \n",
       "211219            0         0      0            0       0        0        0   \n",
       "211220            0         0      0            0       0        0        0   \n",
       "211221            0         0      0            0       0        0        0   \n",
       "211222            0         0      0            0       0        0        0   \n",
       "211223            0         0      0            0       0        0        0   \n",
       "\n",
       "        surprise  neutral  \n",
       "0              0        0  \n",
       "2              0        1  \n",
       "3              0        0  \n",
       "4              0        1  \n",
       "5              0        0  \n",
       "...          ...      ...  \n",
       "211219         0        0  \n",
       "211220         0        0  \n",
       "211221         0        0  \n",
       "211222         0        0  \n",
       "211223         0        0  \n",
       "\n",
       "[171820 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/GoEmotions.csv\")\n",
    "df_clean = clean_df(df)\n",
    "# r, c = df_clean.shape\n",
    "# print(f\"The data has {r} row and {c} columns\")\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>level0</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>dis_sad</td>\n",
       "      <td>dis_sad_gri</td>\n",
       "      <td>rem_emb_dis_sad_gri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>37</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>18</td>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "      <td>exc_joy_lov</td>\n",
       "      <td>amu_exc_joy_lov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Falcon.</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Right? Considering it’s such an important document, I should know the damned thing backwards and forwards... thanks again for the help!</td>\n",
       "      <td>eespn2i</td>\n",
       "      <td>ImperialBoss</td>\n",
       "      <td>TrueReddit</td>\n",
       "      <td>61</td>\n",
       "      <td>gratitude</td>\n",
       "      <td>gra_rel</td>\n",
       "      <td>pri_adm_gra_rel</td>\n",
       "      <td>pri_adm_gra_rel_app_rea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211219</th>\n",
       "      <td>Well, I'm glad you're out of all that now. How awful. The way they act, they make you think healthy boundaries are you being hostile.</td>\n",
       "      <td>ed89acy</td>\n",
       "      <td>pompompompi</td>\n",
       "      <td>raisedbynarcissists</td>\n",
       "      <td>2</td>\n",
       "      <td>joy</td>\n",
       "      <td>exc_joy</td>\n",
       "      <td>exc_joy_lov</td>\n",
       "      <td>amu_exc_joy_lov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>Everyone likes [NAME].</td>\n",
       "      <td>ee6pagw</td>\n",
       "      <td>Senshado</td>\n",
       "      <td>heroesofthestorm</td>\n",
       "      <td>16</td>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "      <td>exc_joy_lov</td>\n",
       "      <td>amu_exc_joy_lov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>Well when you’ve imported about a gazillion of them I or your country it’s gets serious.</td>\n",
       "      <td>ef28nod</td>\n",
       "      <td>5inchloser</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>15</td>\n",
       "      <td>caring</td>\n",
       "      <td>caring</td>\n",
       "      <td>des_opt_car</td>\n",
       "      <td>des_opt_car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>ee8hse1</td>\n",
       "      <td>springt1me</td>\n",
       "      <td>shittyfoodporn</td>\n",
       "      <td>70</td>\n",
       "      <td>admiration</td>\n",
       "      <td>pri_adm</td>\n",
       "      <td>pri_adm_gra_rel</td>\n",
       "      <td>pri_adm_gra_rel_app_rea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here, it's usually criticized horribly off base. It needs to grow some balls and actually enforce things.</td>\n",
       "      <td>edrhoxh</td>\n",
       "      <td>enamedata</td>\n",
       "      <td>medicine</td>\n",
       "      <td>4</td>\n",
       "      <td>anger</td>\n",
       "      <td>ang_ann</td>\n",
       "      <td>dis_ang_ann</td>\n",
       "      <td>dis_ang_ann_dis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171820 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                        text  \\\n",
       "0                                                                                                                                            That game hurt.   \n",
       "2                                                                                                             You do right, if you don't care then fuck 'em!   \n",
       "3                                                                                                                                         Man I love reddit.   \n",
       "4                                                                                                       [NAME] was nowhere near them, he was by the Falcon.    \n",
       "5                    Right? Considering it’s such an important document, I should know the damned thing backwards and forwards... thanks again for the help!   \n",
       "...                                                                                                                                                      ...   \n",
       "211219                 Well, I'm glad you're out of all that now. How awful. The way they act, they make you think healthy boundaries are you being hostile.   \n",
       "211220                                                                                                                                Everyone likes [NAME].   \n",
       "211221                                                              Well when you’ve imported about a gazillion of them I or your country it’s gets serious.   \n",
       "211222                                                                                                                                    That looks amazing   \n",
       "211223  The FDA has plenty to criticize. But like here, it's usually criticized horribly off base. It needs to grow some balls and actually enforce things.    \n",
       "\n",
       "             id               author            subreddit  rater_id  \\\n",
       "0       eew5j0j                Brdd9                  nrl         1   \n",
       "2       ed2mah1             Labalool          confessions        37   \n",
       "3       eeibobj        MrsRobertshaw             facepalm        18   \n",
       "4       eda6yn6  American_Fascist713  starwarsspeculation         2   \n",
       "5       eespn2i         ImperialBoss           TrueReddit        61   \n",
       "...         ...                  ...                  ...       ...   \n",
       "211219  ed89acy          pompompompi  raisedbynarcissists         2   \n",
       "211220  ee6pagw             Senshado     heroesofthestorm        16   \n",
       "211221  ef28nod           5inchloser          nottheonion        15   \n",
       "211222  ee8hse1           springt1me       shittyfoodporn        70   \n",
       "211223  edrhoxh            enamedata             medicine         4   \n",
       "\n",
       "            level0   level1           level2                   level3  \n",
       "0          sadness  dis_sad      dis_sad_gri      rem_emb_dis_sad_gri  \n",
       "2          neutral  neutral          neutral                  neutral  \n",
       "3             love     love      exc_joy_lov          amu_exc_joy_lov  \n",
       "4          neutral  neutral          neutral                  neutral  \n",
       "5        gratitude  gra_rel  pri_adm_gra_rel  pri_adm_gra_rel_app_rea  \n",
       "...            ...      ...              ...                      ...  \n",
       "211219         joy  exc_joy      exc_joy_lov          amu_exc_joy_lov  \n",
       "211220        love     love      exc_joy_lov          amu_exc_joy_lov  \n",
       "211221      caring   caring      des_opt_car              des_opt_car  \n",
       "211222  admiration  pri_adm  pri_adm_gra_rel  pri_adm_gra_rel_app_rea  \n",
       "211223       anger  ang_ann      dis_ang_ann          dis_ang_ann_dis  \n",
       "\n",
       "[171820 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_df = create_clustered_df(df_clean)\n",
    "# r, c = clustered_df.shape\n",
    "# print(f\"The data has {r} row and {c} columns\")\n",
    "clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>level0</th>\n",
       "      <th>plutchik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>betrübt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>37</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>18</td>\n",
       "      <td>love</td>\n",
       "      <td>verliebt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Falcon.</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Right? Considering it’s such an important document, I should know the damned thing backwards and forwards... thanks again for the help!</td>\n",
       "      <td>eespn2i</td>\n",
       "      <td>ImperialBoss</td>\n",
       "      <td>TrueReddit</td>\n",
       "      <td>61</td>\n",
       "      <td>gratitude</td>\n",
       "      <td>ehrfürchtig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211219</th>\n",
       "      <td>Well, I'm glad you're out of all that now. How awful. The way they act, they make you think healthy boundaries are you being hostile.</td>\n",
       "      <td>ed89acy</td>\n",
       "      <td>pompompompi</td>\n",
       "      <td>raisedbynarcissists</td>\n",
       "      <td>2</td>\n",
       "      <td>joy</td>\n",
       "      <td>begeistert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>Everyone likes [NAME].</td>\n",
       "      <td>ee6pagw</td>\n",
       "      <td>Senshado</td>\n",
       "      <td>heroesofthestorm</td>\n",
       "      <td>16</td>\n",
       "      <td>love</td>\n",
       "      <td>verliebt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>Well when you’ve imported about a gazillion of them I or your country it’s gets serious.</td>\n",
       "      <td>ef28nod</td>\n",
       "      <td>5inchloser</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>15</td>\n",
       "      <td>caring</td>\n",
       "      <td>bewundernd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>ee8hse1</td>\n",
       "      <td>springt1me</td>\n",
       "      <td>shittyfoodporn</td>\n",
       "      <td>70</td>\n",
       "      <td>admiration</td>\n",
       "      <td>bewundernd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here, it's usually criticized horribly off base. It needs to grow some balls and actually enforce things.</td>\n",
       "      <td>edrhoxh</td>\n",
       "      <td>enamedata</td>\n",
       "      <td>medicine</td>\n",
       "      <td>4</td>\n",
       "      <td>anger</td>\n",
       "      <td>wütend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171820 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                        text  \\\n",
       "0                                                                                                                                            That game hurt.   \n",
       "2                                                                                                             You do right, if you don't care then fuck 'em!   \n",
       "3                                                                                                                                         Man I love reddit.   \n",
       "4                                                                                                       [NAME] was nowhere near them, he was by the Falcon.    \n",
       "5                    Right? Considering it’s such an important document, I should know the damned thing backwards and forwards... thanks again for the help!   \n",
       "...                                                                                                                                                      ...   \n",
       "211219                 Well, I'm glad you're out of all that now. How awful. The way they act, they make you think healthy boundaries are you being hostile.   \n",
       "211220                                                                                                                                Everyone likes [NAME].   \n",
       "211221                                                              Well when you’ve imported about a gazillion of them I or your country it’s gets serious.   \n",
       "211222                                                                                                                                    That looks amazing   \n",
       "211223  The FDA has plenty to criticize. But like here, it's usually criticized horribly off base. It needs to grow some balls and actually enforce things.    \n",
       "\n",
       "             id               author            subreddit  rater_id  \\\n",
       "0       eew5j0j                Brdd9                  nrl         1   \n",
       "2       ed2mah1             Labalool          confessions        37   \n",
       "3       eeibobj        MrsRobertshaw             facepalm        18   \n",
       "4       eda6yn6  American_Fascist713  starwarsspeculation         2   \n",
       "5       eespn2i         ImperialBoss           TrueReddit        61   \n",
       "...         ...                  ...                  ...       ...   \n",
       "211219  ed89acy          pompompompi  raisedbynarcissists         2   \n",
       "211220  ee6pagw             Senshado     heroesofthestorm        16   \n",
       "211221  ef28nod           5inchloser          nottheonion        15   \n",
       "211222  ee8hse1           springt1me       shittyfoodporn        70   \n",
       "211223  edrhoxh            enamedata             medicine         4   \n",
       "\n",
       "            level0     plutchik  \n",
       "0          sadness      betrübt  \n",
       "2          neutral      neutral  \n",
       "3             love     verliebt  \n",
       "4          neutral      neutral  \n",
       "5        gratitude  ehrfürchtig  \n",
       "...            ...          ...  \n",
       "211219         joy   begeistert  \n",
       "211220        love     verliebt  \n",
       "211221      caring   bewundernd  \n",
       "211222  admiration   bewundernd  \n",
       "211223       anger       wütend  \n",
       "\n",
       "[171820 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plutchik_df = create_plutchik_df(df_clean)\n",
    "# r, c = plutchik_df.shape\n",
    "# print(f\"The data has {r} row and {c} columns\")\n",
    "plutchik_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT for level 0 -> 27 emotions\n",
    "following: https://huggingface.co/docs/transformers/tasks/sequence_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'neutral', 'love', 'gratitude', 'disapproval',\n",
       "       'amusement', 'disappointment', 'realization', 'admiration',\n",
       "       'annoyance', 'confusion', 'optimism', 'excitement', 'caring',\n",
       "       'remorse', 'joy', 'approval', 'embarrassment', 'surprise',\n",
       "       'curiosity', 'anger', 'grief', 'disgust', 'pride', 'desire',\n",
       "       'relief', 'fear', 'nervousness'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_df.level0.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\") # differentiation between upper and lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: 'sadness', 1: 'neutral', 2: 'love', 3: 'gratitude', 4: 'disapproval',\n",
    "       5: 'amusement', 6: 'disappointment', 7: 'realization', 8: 'admiration', 9:\n",
    "       'annoyance', 10: 'confusion', 11: 'optimism', 12: 'excitement', 13: 'caring',\n",
    "       14: 'remorse', 15: 'joy', 16: 'approval', 17: 'embarrassment', 18: 'surprise',\n",
    "       19: 'curiosity', 20: 'anger', 21: 'grief', 22: 'disgust', 23: 'pride', 24: 'desire',\n",
    "       25: 'relief', 26: 'fear', 27: 'nervousness'}\n",
    "\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>level0</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58047</th>\n",
       "      <td>I actually heard [NAME] inviting [NAME] and [NAME] to be on her show, after the interview with [NAME] ex wife.</td>\n",
       "      <td>ed0xjb6</td>\n",
       "      <td>unidrogon</td>\n",
       "      <td>90dayfianceuncensored</td>\n",
       "      <td>70</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175996</th>\n",
       "      <td>It really do</td>\n",
       "      <td>ee6rr87</td>\n",
       "      <td>Slats04</td>\n",
       "      <td>forhonor</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121014</th>\n",
       "      <td>Wanted something more on Imperius Angiris Wrath ulti at lvl 20... :'( Nice buff to Valorus Pursuit though!</td>\n",
       "      <td>ees9uev</td>\n",
       "      <td>Remus88Romulus</td>\n",
       "      <td>heroesofthestorm</td>\n",
       "      <td>42</td>\n",
       "      <td>sadness</td>\n",
       "      <td>dis_sad</td>\n",
       "      <td>dis_sad_gri</td>\n",
       "      <td>rem_emb_dis_sad_gri</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171647</th>\n",
       "      <td>I hope xe had a nice talk with the premier</td>\n",
       "      <td>ef6g4jt</td>\n",
       "      <td>thrown_41232</td>\n",
       "      <td>ontario</td>\n",
       "      <td>15</td>\n",
       "      <td>optimism</td>\n",
       "      <td>des_opt</td>\n",
       "      <td>des_opt_car</td>\n",
       "      <td>des_opt_car</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>Seriously!? Wouldn't a guy do the same thing if a girl didn't even attempt to get him off?</td>\n",
       "      <td>eecrhn4</td>\n",
       "      <td>hangry_potato</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>2</td>\n",
       "      <td>curiosity</td>\n",
       "      <td>cur_con</td>\n",
       "      <td>sur_cur_con</td>\n",
       "      <td>sur_cur_con</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158031</th>\n",
       "      <td>That’s very admirable and courageous of her. I appreciate the many women that are doing that here on Reddit as well.</td>\n",
       "      <td>eez329z</td>\n",
       "      <td>nliwtbat</td>\n",
       "      <td>childfree</td>\n",
       "      <td>67</td>\n",
       "      <td>admiration</td>\n",
       "      <td>pri_adm</td>\n",
       "      <td>pri_adm_gra_rel</td>\n",
       "      <td>pri_adm_gra_rel_app_rea</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79736</th>\n",
       "      <td>4 lives essentially, its insane</td>\n",
       "      <td>ef1u8dh</td>\n",
       "      <td>trkh</td>\n",
       "      <td>self</td>\n",
       "      <td>70</td>\n",
       "      <td>embarrassment</td>\n",
       "      <td>embarrassment</td>\n",
       "      <td>embarrassment</td>\n",
       "      <td>embarrassment</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71777</th>\n",
       "      <td>I regret that I understand that reference :(</td>\n",
       "      <td>ee18oid</td>\n",
       "      <td>slinkslowdown</td>\n",
       "      <td>tifu</td>\n",
       "      <td>72</td>\n",
       "      <td>remorse</td>\n",
       "      <td>rem_emb</td>\n",
       "      <td>rem_emb</td>\n",
       "      <td>rem_emb_dis_sad_gri</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>I thought you were just going to wait her out. You actually engineered her loss of space to someone else. WELL DONE!!!!</td>\n",
       "      <td>ef7jkmz</td>\n",
       "      <td>Fluffydress</td>\n",
       "      <td>pettyrevenge</td>\n",
       "      <td>41</td>\n",
       "      <td>admiration</td>\n",
       "      <td>pri_adm</td>\n",
       "      <td>pri_adm_gra_rel</td>\n",
       "      <td>pri_adm_gra_rel_app_rea</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125048</th>\n",
       "      <td>And riding one makes you look like a man trying to be tough during his mid life crisis.</td>\n",
       "      <td>eerdryr</td>\n",
       "      <td>Blacky05</td>\n",
       "      <td>forwardsfromgrandma</td>\n",
       "      <td>20</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                           text  \\\n",
       "58047            I actually heard [NAME] inviting [NAME] and [NAME] to be on her show, after the interview with [NAME] ex wife.   \n",
       "175996                                                                                                             It really do   \n",
       "121014               Wanted something more on Imperius Angiris Wrath ulti at lvl 20... :'( Nice buff to Valorus Pursuit though!   \n",
       "171647                                                                               I hope xe had a nice talk with the premier   \n",
       "3222                                 Seriously!? Wouldn't a guy do the same thing if a girl didn't even attempt to get him off?   \n",
       "...                                                                                                                         ...   \n",
       "158031     That’s very admirable and courageous of her. I appreciate the many women that are doing that here on Reddit as well.   \n",
       "79736                                                                                           4 lives essentially, its insane   \n",
       "71777                                                                              I regret that I understand that reference :(   \n",
       "2842    I thought you were just going to wait her out. You actually engineered her loss of space to someone else. WELL DONE!!!!   \n",
       "125048                                  And riding one makes you look like a man trying to be tough during his mid life crisis.   \n",
       "\n",
       "             id          author              subreddit  rater_id  \\\n",
       "58047   ed0xjb6       unidrogon  90dayfianceuncensored        70   \n",
       "175996  ee6rr87         Slats04               forhonor         4   \n",
       "121014  ees9uev  Remus88Romulus       heroesofthestorm        42   \n",
       "171647  ef6g4jt    thrown_41232                ontario        15   \n",
       "3222    eecrhn4   hangry_potato               AskWomen         2   \n",
       "...         ...             ...                    ...       ...   \n",
       "158031  eez329z        nliwtbat              childfree        67   \n",
       "79736   ef1u8dh            trkh                   self        70   \n",
       "71777   ee18oid   slinkslowdown                   tifu        72   \n",
       "2842    ef7jkmz     Fluffydress           pettyrevenge        41   \n",
       "125048  eerdryr        Blacky05    forwardsfromgrandma        20   \n",
       "\n",
       "               level0         level1           level2  \\\n",
       "58047         neutral        neutral          neutral   \n",
       "175996        neutral        neutral          neutral   \n",
       "121014        sadness        dis_sad      dis_sad_gri   \n",
       "171647       optimism        des_opt      des_opt_car   \n",
       "3222        curiosity        cur_con      sur_cur_con   \n",
       "...               ...            ...              ...   \n",
       "158031     admiration        pri_adm  pri_adm_gra_rel   \n",
       "79736   embarrassment  embarrassment    embarrassment   \n",
       "71777         remorse        rem_emb          rem_emb   \n",
       "2842       admiration        pri_adm  pri_adm_gra_rel   \n",
       "125048        neutral        neutral          neutral   \n",
       "\n",
       "                         level3  label  \n",
       "58047                   neutral      1  \n",
       "175996                  neutral      1  \n",
       "121014      rem_emb_dis_sad_gri      0  \n",
       "171647              des_opt_car     11  \n",
       "3222                sur_cur_con     19  \n",
       "...                         ...    ...  \n",
       "158031  pri_adm_gra_rel_app_rea      8  \n",
       "79736             embarrassment     17  \n",
       "71777       rem_emb_dis_sad_gri     14  \n",
       "2842    pri_adm_gra_rel_app_rea      8  \n",
       "125048                  neutral      1  \n",
       "\n",
       "[20000 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a sample for local tests\n",
    "\n",
    "# dataset = clustered_df.sample(n=1000, replace=False, random_state=123)\n",
    "dataset = clustered_df.sample(n=20000, replace=False, random_state=123)\n",
    "\n",
    "dataset[\"label\"] = dataset[\"level0\"].map(label2id.get) # to add column label map individual entries of emotions to ID\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split the training data\n",
    "from datasets import Dataset\n",
    "\n",
    "training_data = dataset.groupby(\"level0\").sample(frac=0.8, random_state=25) # stratified sampling\n",
    "testing_data = dataset.drop(training_data.index)\n",
    "\n",
    "training_data = Dataset.from_pandas(training_data) # create transformers compatible dataset from dataframe\n",
    "testing_data = Dataset.from_pandas(testing_data)\n",
    "\n",
    "def tokenize_function(examples): # replace representation of data, convert column text to tensor-based representation\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_training_data = training_data.map(tokenize_function, batched=True) # convert text to tensor form\n",
    "tokenized_testing_data = testing_data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'id', 'author', 'subreddit', 'rater_id', 'level0', 'level1', 'level2', 'level3', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 16002\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>level0</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133015</th>\n",
       "      <td>The fact that the passenger gives a thumbs up drives me crazy</td>\n",
       "      <td>eej9uky</td>\n",
       "      <td>dantheman7480</td>\n",
       "      <td>SweatyPalms</td>\n",
       "      <td>11</td>\n",
       "      <td>annoyance</td>\n",
       "      <td>ang_ann</td>\n",
       "      <td>dis_ang_ann</td>\n",
       "      <td>dis_ang_ann_dis</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  \\\n",
       "133015  The fact that the passenger gives a thumbs up drives me crazy   \n",
       "\n",
       "             id         author    subreddit  rater_id     level0   level1  \\\n",
       "133015  eej9uky  dantheman7480  SweatyPalms        11  annoyance  ang_ann   \n",
       "\n",
       "             level2           level3  label  \n",
       "133015  dis_ang_ann  dis_ang_ann_dis      9  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annoyance_example = random.sample(list(dataset.id[dataset.level0 == \"annoyance\"]), k=1) # example for annoyance\n",
    "dataset.query('id==@annoyance_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>level0</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22852</th>\n",
       "      <td>I wish everything the I was going through was a hallucination</td>\n",
       "      <td>edyxv3p</td>\n",
       "      <td>1000asses</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>81</td>\n",
       "      <td>desire</td>\n",
       "      <td>des_opt</td>\n",
       "      <td>des_opt_car</td>\n",
       "      <td>des_opt_car</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                text       id  \\\n",
       "22852  I wish everything the I was going through was a hallucination  edyxv3p   \n",
       "\n",
       "          author     subreddit  rater_id  level0   level1       level2  \\\n",
       "22852  1000asses  mentalhealth        81  desire  des_opt  des_opt_car   \n",
       "\n",
       "            level3  label  \n",
       "22852  des_opt_car     24  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desire_example = random.sample(list(dataset.id[dataset.level0 == \"desire\"]), k=1) # example for desire\n",
    "dataset.query('id==@desire_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level0\n",
      "neutral           6482\n",
      "approval          1311\n",
      "admiration        1278\n",
      "annoyance          956\n",
      "disapproval        859\n",
      "gratitude          843\n",
      "amusement          695\n",
      "curiosity          689\n",
      "anger              604\n",
      "confusion          589\n",
      "love               582\n",
      "joy                539\n",
      "disappointment     516\n",
      "optimism           501\n",
      "realization        492\n",
      "caring             454\n",
      "sadness            452\n",
      "surprise           391\n",
      "excitement         371\n",
      "disgust            332\n",
      "desire             247\n",
      "fear               208\n",
      "remorse            178\n",
      "embarrassment      152\n",
      "relief              95\n",
      "pride               82\n",
      "nervousness         70\n",
      "grief               32\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if data set is balanced\n",
    "classCounts = dataset.level0.value_counts() \n",
    "print(classCounts)\n",
    "# -> not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfDocuments = len(dataset)\n",
    "numberOfDocuments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # Padding -> map all tensors to the same size\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\") # define evaluation method -> quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred): # function calculation metric\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-cased\", num_labels=28, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ro412kzae/.local/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13340' max='13340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13340/13340 1:44:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.151000</td>\n",
       "      <td>2.010411</td>\n",
       "      <td>0.438969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.828000</td>\n",
       "      <td>1.983874</td>\n",
       "      <td>0.438469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.554000</td>\n",
       "      <td>2.073496</td>\n",
       "      <td>0.420960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.239900</td>\n",
       "      <td>2.232963</td>\n",
       "      <td>0.409455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.008000</td>\n",
       "      <td>2.437846</td>\n",
       "      <td>0.384692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.824700</td>\n",
       "      <td>2.650943</td>\n",
       "      <td>0.381441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.664900</td>\n",
       "      <td>2.823755</td>\n",
       "      <td>0.376188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.560500</td>\n",
       "      <td>2.986976</td>\n",
       "      <td>0.379190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.485200</td>\n",
       "      <td>3.110445</td>\n",
       "      <td>0.380190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.392800</td>\n",
       "      <td>3.175715</td>\n",
       "      <td>0.374937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13340, training_loss=1.0693066907250721, metrics={'train_runtime': 6260.2805, 'train_samples_per_second': 25.561, 'train_steps_per_second': 2.131, 'total_flos': 4.211285975801856e+16, 'train_loss': 1.0693066907250721, 'epoch': 10.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/model_level0\",\n",
    "    learning_rate=2e-5,  # standard\n",
    "    per_device_train_batch_size=12, # size in which chunks are entered into the network, on how many data parallel weights are trained\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\", # save model per epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False #,\n",
    "    #label_names=[\"level0\"],\n",
    ")\n",
    "\n",
    "# IMPORTANT: Set: Model, dataset, ... , define learning process, metrics, ...\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_training_data,\n",
    "    eval_dataset=tokenized_testing_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics  \n",
    ")\n",
    "\n",
    "#checkpointing\n",
    "#use cuda\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../models/model_level0_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/20000 [00:00<09:05, 36.64it/s]/home/sc.uni-leipzig.de/ro412kzae/.local/lib/python3.11/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 20000/20000 [03:54<00:00, 85.36it/s]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model=\"../models/model_level0_sample\",device=0) # method pipeline -> string for text classificaton, folder, device (graphics card)\n",
    "results = [classifier(text,truncation=True) for text in tqdm(dataset.text.to_list())] # list comprehension over all texts, tokenization in model, truncation -> padding too long texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [tmp[0] for tmp in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results # list of dictionaries with labels, score -> decision and how high activation function for decision was\n",
    "pd.DataFrame(results).to_pickle(\"../results/results_level0_sample.pkl\")  # convert as dataframe, pick, safe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.556368</td>\n",
       "      <td>ed0xjb6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.554485</td>\n",
       "      <td>ee6rr87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.480834</td>\n",
       "      <td>ees9uev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>optimism</td>\n",
       "      <td>0.547510</td>\n",
       "      <td>ef6g4jt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.278006</td>\n",
       "      <td>eecrhn4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>admiration</td>\n",
       "      <td>0.652712</td>\n",
       "      <td>eez329z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>disgust</td>\n",
       "      <td>0.193177</td>\n",
       "      <td>ef1u8dh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>remorse</td>\n",
       "      <td>0.379275</td>\n",
       "      <td>ee18oid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.424216</td>\n",
       "      <td>ef7jkmz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.461723</td>\n",
       "      <td>eerdryr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label     score       id\n",
       "0         neutral  0.556368  ed0xjb6\n",
       "1         neutral  0.554485  ee6rr87\n",
       "2         neutral  0.480834  ees9uev\n",
       "3        optimism  0.547510  ef6g4jt\n",
       "4         neutral  0.278006  eecrhn4\n",
       "...           ...       ...      ...\n",
       "19995  admiration  0.652712  eez329z\n",
       "19996     disgust  0.193177  ef1u8dh\n",
       "19997     remorse  0.379275  ee18oid\n",
       "19998     neutral  0.424216  ef7jkmz\n",
       "19999     neutral  0.461723  eerdryr\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame.from_dict(results)\n",
    "df_id =  pd.DataFrame(dataset[\"id\"])\n",
    "df_id = df_id.reset_index()\n",
    "df_results[\"id\"] = df_id[\"id\"]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifies = pd.merge(dataset, df_results, on='id', how='left')\n",
    "\n",
    "# merge classified data with original training data\n",
    "# combine data with training data, concatenate results results and training data\n",
    "# compare -> calculate f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifies.to_pickle(\"../results/data_classified_level0_sample.pkl\")  \n",
    "# data_classifies = pd.read_pickle(\"../results/data_classified_level0_1epoch.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>level0</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>label_x</th>\n",
       "      <th>label_y</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I actually heard [NAME] inviting [NAME] and [NAME] to be on her show, after the interview with [NAME] ex wife.</td>\n",
       "      <td>ed0xjb6</td>\n",
       "      <td>unidrogon</td>\n",
       "      <td>90dayfianceuncensored</td>\n",
       "      <td>70</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.556368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It really do</td>\n",
       "      <td>ee6rr87</td>\n",
       "      <td>Slats04</td>\n",
       "      <td>forhonor</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.554485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wanted something more on Imperius Angiris Wrath ulti at lvl 20... :'( Nice buff to Valorus Pursuit though!</td>\n",
       "      <td>ees9uev</td>\n",
       "      <td>Remus88Romulus</td>\n",
       "      <td>heroesofthestorm</td>\n",
       "      <td>42</td>\n",
       "      <td>sadness</td>\n",
       "      <td>dis_sad</td>\n",
       "      <td>dis_sad_gri</td>\n",
       "      <td>rem_emb_dis_sad_gri</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.480834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I hope xe had a nice talk with the premier</td>\n",
       "      <td>ef6g4jt</td>\n",
       "      <td>thrown_41232</td>\n",
       "      <td>ontario</td>\n",
       "      <td>15</td>\n",
       "      <td>optimism</td>\n",
       "      <td>des_opt</td>\n",
       "      <td>des_opt_car</td>\n",
       "      <td>des_opt_car</td>\n",
       "      <td>11</td>\n",
       "      <td>optimism</td>\n",
       "      <td>0.547510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seriously!? Wouldn't a guy do the same thing if a girl didn't even attempt to get him off?</td>\n",
       "      <td>eecrhn4</td>\n",
       "      <td>hangry_potato</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>2</td>\n",
       "      <td>curiosity</td>\n",
       "      <td>cur_con</td>\n",
       "      <td>sur_cur_con</td>\n",
       "      <td>sur_cur_con</td>\n",
       "      <td>19</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.278006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25597</th>\n",
       "      <td>4 lives essentially, its insane</td>\n",
       "      <td>ef1u8dh</td>\n",
       "      <td>trkh</td>\n",
       "      <td>self</td>\n",
       "      <td>70</td>\n",
       "      <td>embarrassment</td>\n",
       "      <td>embarrassment</td>\n",
       "      <td>embarrassment</td>\n",
       "      <td>embarrassment</td>\n",
       "      <td>17</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.193177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25598</th>\n",
       "      <td>I regret that I understand that reference :(</td>\n",
       "      <td>ee18oid</td>\n",
       "      <td>slinkslowdown</td>\n",
       "      <td>tifu</td>\n",
       "      <td>72</td>\n",
       "      <td>remorse</td>\n",
       "      <td>rem_emb</td>\n",
       "      <td>rem_emb</td>\n",
       "      <td>rem_emb_dis_sad_gri</td>\n",
       "      <td>14</td>\n",
       "      <td>remorse</td>\n",
       "      <td>0.379275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25599</th>\n",
       "      <td>I thought you were just going to wait her out. You actually engineered her loss of space to someone else. WELL DONE!!!!</td>\n",
       "      <td>ef7jkmz</td>\n",
       "      <td>Fluffydress</td>\n",
       "      <td>pettyrevenge</td>\n",
       "      <td>41</td>\n",
       "      <td>admiration</td>\n",
       "      <td>pri_adm</td>\n",
       "      <td>pri_adm_gra_rel</td>\n",
       "      <td>pri_adm_gra_rel_app_rea</td>\n",
       "      <td>8</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.424216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25600</th>\n",
       "      <td>And riding one makes you look like a man trying to be tough during his mid life crisis.</td>\n",
       "      <td>eerdryr</td>\n",
       "      <td>Blacky05</td>\n",
       "      <td>forwardsfromgrandma</td>\n",
       "      <td>20</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.461723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25601</th>\n",
       "      <td>And riding one makes you look like a man trying to be tough during his mid life crisis.</td>\n",
       "      <td>eerdryr</td>\n",
       "      <td>Blacky05</td>\n",
       "      <td>forwardsfromgrandma</td>\n",
       "      <td>20</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.461723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25602 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          text  \\\n",
       "0               I actually heard [NAME] inviting [NAME] and [NAME] to be on her show, after the interview with [NAME] ex wife.   \n",
       "1                                                                                                                 It really do   \n",
       "2                   Wanted something more on Imperius Angiris Wrath ulti at lvl 20... :'( Nice buff to Valorus Pursuit though!   \n",
       "3                                                                                   I hope xe had a nice talk with the premier   \n",
       "4                                   Seriously!? Wouldn't a guy do the same thing if a girl didn't even attempt to get him off?   \n",
       "...                                                                                                                        ...   \n",
       "25597                                                                                          4 lives essentially, its insane   \n",
       "25598                                                                             I regret that I understand that reference :(   \n",
       "25599  I thought you were just going to wait her out. You actually engineered her loss of space to someone else. WELL DONE!!!!   \n",
       "25600                                  And riding one makes you look like a man trying to be tough during his mid life crisis.   \n",
       "25601                                  And riding one makes you look like a man trying to be tough during his mid life crisis.   \n",
       "\n",
       "            id          author              subreddit  rater_id  \\\n",
       "0      ed0xjb6       unidrogon  90dayfianceuncensored        70   \n",
       "1      ee6rr87         Slats04               forhonor         4   \n",
       "2      ees9uev  Remus88Romulus       heroesofthestorm        42   \n",
       "3      ef6g4jt    thrown_41232                ontario        15   \n",
       "4      eecrhn4   hangry_potato               AskWomen         2   \n",
       "...        ...             ...                    ...       ...   \n",
       "25597  ef1u8dh            trkh                   self        70   \n",
       "25598  ee18oid   slinkslowdown                   tifu        72   \n",
       "25599  ef7jkmz     Fluffydress           pettyrevenge        41   \n",
       "25600  eerdryr        Blacky05    forwardsfromgrandma        20   \n",
       "25601  eerdryr        Blacky05    forwardsfromgrandma        20   \n",
       "\n",
       "              level0         level1           level2                   level3  \\\n",
       "0            neutral        neutral          neutral                  neutral   \n",
       "1            neutral        neutral          neutral                  neutral   \n",
       "2            sadness        dis_sad      dis_sad_gri      rem_emb_dis_sad_gri   \n",
       "3           optimism        des_opt      des_opt_car              des_opt_car   \n",
       "4          curiosity        cur_con      sur_cur_con              sur_cur_con   \n",
       "...              ...            ...              ...                      ...   \n",
       "25597  embarrassment  embarrassment    embarrassment            embarrassment   \n",
       "25598        remorse        rem_emb          rem_emb      rem_emb_dis_sad_gri   \n",
       "25599     admiration        pri_adm  pri_adm_gra_rel  pri_adm_gra_rel_app_rea   \n",
       "25600        neutral        neutral          neutral                  neutral   \n",
       "25601        neutral        neutral          neutral                  neutral   \n",
       "\n",
       "       label_x   label_y     score  \n",
       "0            1   neutral  0.556368  \n",
       "1            1   neutral  0.554485  \n",
       "2            0   neutral  0.480834  \n",
       "3           11  optimism  0.547510  \n",
       "4           19   neutral  0.278006  \n",
       "...        ...       ...       ...  \n",
       "25597       17   disgust  0.193177  \n",
       "25598       14   remorse  0.379275  \n",
       "25599        8   neutral  0.424216  \n",
       "25600        1   neutral  0.461723  \n",
       "25601        1   neutral  0.461723  \n",
       "\n",
       "[25602 rows x 12 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_classifies # contain gold standard and ergbnis cluster -> calculate F1, Precision, Recall\n",
    "# label -> assigned by classifier (?????)\n",
    "# level0 -> original label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data_classifies.query(f'id in {tokenized_testing_data[\"id\"]}')\n",
    "# tokenized_testing_data: Daten der Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "       sadness       0.58      0.59      0.59       426\n",
      "       neutral       0.46      0.71      0.56       240\n",
      "          love       0.42      0.36      0.39       224\n",
      "     gratitude       0.20      0.10      0.13       347\n",
      "   disapproval       0.34      0.16      0.21       491\n",
      "     amusement       0.44      0.20      0.28       178\n",
      "disappointment       0.58      0.13      0.21       204\n",
      "   realization       0.76      0.06      0.11       211\n",
      "    admiration       0.38      0.13      0.19        70\n",
      "     annoyance       0.57      0.07      0.12       192\n",
      "     confusion       0.23      0.09      0.13       302\n",
      "      optimism       0.28      0.18      0.22       115\n",
      "    excitement       0.58      0.15      0.23        48\n",
      "        caring       0.25      0.03      0.05       134\n",
      "       remorse       0.66      0.43      0.52        77\n",
      "           joy       0.86      0.72      0.79       261\n",
      "      approval       0.00      0.00      0.00        13\n",
      " embarrassment       0.38      0.46      0.42       177\n",
      "      surprise       0.59      0.72      0.65       232\n",
      "     curiosity       0.00      0.00      0.00        25\n",
      "         anger       0.45      0.79      0.57      2271\n",
      "         grief       0.61      0.33      0.43       179\n",
      "       disgust       0.00      0.00      0.00        27\n",
      "         pride       0.00      0.00      0.00       184\n",
      "        desire       0.00      0.00      0.00        29\n",
      "        relief       0.38      0.60      0.47        58\n",
      "          fear       0.47      0.30      0.37       140\n",
      "   nervousness       0.30      0.32      0.31       142\n",
      "\n",
      "      accuracy                           0.46      6997\n",
      "     macro avg       0.38      0.27      0.28      6997\n",
      "  weighted avg       0.44      0.46      0.40      6997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/jupyter/conda/envs/jupyter/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/jupyter/conda/envs/jupyter/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/jupyter/conda/envs/jupyter/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_names = ['sadness', 'neutral', 'love', 'gratitude', 'disapproval',\n",
    "       'amusement', 'disappointment', 'realization', 'admiration',\n",
    "       'annoyance', 'confusion', 'optimism', 'excitement', 'caring',\n",
    "       'remorse', 'joy', 'approval', 'embarrassment', 'surprise',\n",
    "       'curiosity', 'anger', 'grief', 'disgust', 'pride', 'desire',\n",
    "       'relief', 'fear', 'nervousness']\n",
    "print(classification_report(test_data.level0, test_data.label_y, target_names=target_names))\n",
    "# level0 -> gold standard , label -> prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.556368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.554485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.480834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>optimism</td>\n",
       "      <td>0.547510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.278006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>admiration</td>\n",
       "      <td>0.652712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>disgust</td>\n",
       "      <td>0.193177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>remorse</td>\n",
       "      <td>0.379275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.424216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.461723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label     score\n",
       "0         neutral  0.556368\n",
       "1         neutral  0.554485\n",
       "2         neutral  0.480834\n",
       "3        optimism  0.547510\n",
       "4         neutral  0.278006\n",
       "...           ...       ...\n",
       "19995  admiration  0.652712\n",
       "19996     disgust  0.193177\n",
       "19997     remorse  0.379275\n",
       "19998     neutral  0.424216\n",
       "19999     neutral  0.461723\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_y\n",
       "neutral           0.528552\n",
       "admiration        0.064448\n",
       "amusement         0.053511\n",
       "gratitude         0.036169\n",
       "approval          0.035935\n",
       "love              0.035818\n",
       "anger             0.032341\n",
       "annoyance         0.031404\n",
       "joy               0.027732\n",
       "surprise          0.023397\n",
       "disapproval       0.022186\n",
       "disgust           0.017381\n",
       "sadness           0.016366\n",
       "optimism          0.015272\n",
       "remorse           0.014413\n",
       "caring            0.014140\n",
       "confusion         0.008554\n",
       "fear              0.006796\n",
       "desire            0.005859\n",
       "excitement        0.003359\n",
       "curiosity         0.003242\n",
       "disappointment    0.002344\n",
       "embarrassment     0.000781\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Classification/Viz\n",
    "#final = pd.concat([dataset, pd.DataFrame.from_dict(results)],axis=1) # attach classified label to data\n",
    "final = data_classifies.copy()\n",
    "final['label_y'].value_counts()/final['label_y'].value_counts().sum() # ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
