{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Text Classification for Emotions using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets huggingface_hub ipywidgets evaluate 'transformers[torch]' torch xformers plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# We need the sys package to load modules from another directory:\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from preprocessing.preprocessors import *\n",
    "from preprocessing.bert_func import *\n",
    "\n",
    "import random\n",
    "import evaluate\n",
    "\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "from plotnine import ggplot, aes, geom_tile, coord_flip,theme,geom_line,labs,element_text\n",
    "from plotnine import scale_x_discrete,geom_vline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/GoEmotions.csv\")\n",
    "df_clean = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 171820 row and 33 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text       id         author  \\\n",
       "0                                 That game hurt.  eew5j0j          Brdd9   \n",
       "2  You do right, if you don't care then fuck 'em!  ed2mah1       Labalool   \n",
       "3                              Man I love reddit.  eeibobj  MrsRobertshaw   \n",
       "\n",
       "     subreddit  rater_id  admiration  amusement  anger  annoyance  approval  \\\n",
       "0          nrl         1           0          0      0          0         0   \n",
       "2  confessions        37           0          0      0          0         0   \n",
       "3     facepalm        18           0          0      0          0         0   \n",
       "\n",
       "   ...  love  nervousness  optimism  pride  realization  relief  remorse  \\\n",
       "0  ...     0            0         0      0            0       0        0   \n",
       "2  ...     0            0         0      0            0       0        0   \n",
       "3  ...     1            0         0      0            0       0        0   \n",
       "\n",
       "   sadness  surprise  neutral  \n",
       "0        1         0        0  \n",
       "2        0         0        1  \n",
       "3        0         0        0  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, c = df_clean.shape\n",
    "print(f\"The data has {r} row and {c} columns\")\n",
    "df_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df = create_df_all_labels(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 171820 row and 10 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>level0</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>plutchik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>dis_sad</td>\n",
       "      <td>dis_sad_gri</td>\n",
       "      <td>rem_emb_dis_sad_gri</td>\n",
       "      <td>grief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>37</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>18</td>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "      <td>exc_joy_lov</td>\n",
       "      <td>amu_exc_joy_lov</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text       id         author  \\\n",
       "0                                 That game hurt.  eew5j0j          Brdd9   \n",
       "2  You do right, if you don't care then fuck 'em!  ed2mah1       Labalool   \n",
       "3                              Man I love reddit.  eeibobj  MrsRobertshaw   \n",
       "\n",
       "     subreddit  rater_id   level0   level1       level2               level3  \\\n",
       "0          nrl         1  sadness  dis_sad  dis_sad_gri  rem_emb_dis_sad_gri   \n",
       "2  confessions        37  neutral  neutral      neutral              neutral   \n",
       "3     facepalm        18     love     love  exc_joy_lov      amu_exc_joy_lov   \n",
       "\n",
       "  plutchik  \n",
       "0    grief  \n",
       "2  neutral  \n",
       "3     love  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "r, c = clustered_df.shape\n",
    "print(f\"The data has {r} row and {c} columns\")\n",
    "clustered_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Classifier\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = \"bert-base-cased\"\n",
    "models_dir = \"../models/bert_base_cased/\"\n",
    "results_dir = \"../results/bert_base_cased/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT for level 0 -> 27 +1 emotions\n",
    "following: https://huggingface.co/docs/transformers/tasks/sequence_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None # default value is 50, max would be \"None\"\n",
    "pd.set_option('display.max_rows', 50) # default value is 10, max would be \"None\"\n",
    "\n",
    "annoyance_example = random.sample(list(clustered_df.id[clustered_df.level0 == \"annoyance\"]), k=1) # example for annoyance\n",
    "clustered_df.query('id==@annoyance_example')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desire_example = random.sample(list(clustered_df.id[clustered_df.level0 == \"desire\"]), k=1) # example for desire\n",
    "clustered_df.query('id==@desire_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral           55298\n",
      "approval          11259\n",
      "admiration        10531\n",
      "annoyance          8342\n",
      "disapproval        7686\n",
      "gratitude          7075\n",
      "amusement          6130\n",
      "curiosity          5885\n",
      "anger              5202\n",
      "love               4957\n",
      "confusion          4938\n",
      "realization        4714\n",
      "disappointment     4706\n",
      "optimism           4519\n",
      "joy                4329\n",
      "sadness            3827\n",
      "caring             3523\n",
      "surprise           3472\n",
      "excitement         3020\n",
      "disgust            2914\n",
      "desire             2147\n",
      "fear               1778\n",
      "remorse            1510\n",
      "embarrassment      1433\n",
      "nervousness         796\n",
      "relief              788\n",
      "pride               690\n",
      "grief               351\n",
      "Name: level0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if data set is balanced\n",
    "classCounts_0 = clustered_df.level0.value_counts() \n",
    "print(classCounts_0)\n",
    "# -> not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171820"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfDocuments_0 = len(clustered_df)\n",
    "numberOfDocuments_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_0, results_0, tokenized_testing_data_0 = get_bert(clustered_df, \"level0\", bert, models_dir, results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.176830</td>\n",
       "      <td>eez4phj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.703029</td>\n",
       "      <td>eeejsh7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.079363</td>\n",
       "      <td>ed8auqx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.420149</td>\n",
       "      <td>ee103qd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.331734</td>\n",
       "      <td>efaudck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>admiration</td>\n",
       "      <td>0.081957</td>\n",
       "      <td>eetak09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>approval</td>\n",
       "      <td>0.110026</td>\n",
       "      <td>edlin87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.214870</td>\n",
       "      <td>ed23fr7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.735096</td>\n",
       "      <td>eeb063d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.362268</td>\n",
       "      <td>eeskl7s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label     score       id\n",
       "0       neutral  0.176830  eez4phj\n",
       "1       neutral  0.703029  eeejsh7\n",
       "2       neutral  0.079363  ed8auqx\n",
       "3       neutral  0.420149  ee103qd\n",
       "4       neutral  0.331734  efaudck\n",
       "..          ...       ...      ...\n",
       "995  admiration  0.081957  eetak09\n",
       "996    approval  0.110026  edlin87\n",
       "997     neutral  0.214870  ed23fr7\n",
       "998     neutral  0.735096  eeb063d\n",
       "999     neutral  0.362268  eeskl7s\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_0 = pd.DataFrame.from_dict(results_0)\n",
    "df_id_0 =  pd.DataFrame(dataset_0[\"id\"])\n",
    "df_id_0 = df_id_0.reset_index()\n",
    "df_results_0[\"id\"] = df_id_0[\"id\"]\n",
    "df_results_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifies_0 = pd.merge(dataset_0, df_results_0, on='id', how='left') # merge classified data with original training data\n",
    "data_classifies_0.to_pickle(results_dir + \"data_classified_level0.pkl\")  \n",
    "data_classifies_0 # contain sgoldstandard and cluster of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_0 = data_classifies_0.query(f'id in {tokenized_testing_data_0[\"id\"]}')\n",
    "# tokenized_testing_data: daten der Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "       sadness       0.25      0.75      0.38        12\n",
      "          love       0.00      0.00      0.00         6\n",
      "     gratitude       0.00      0.00      0.00         7\n",
      "   disapproval       0.50      0.12      0.20         8\n",
      "     amusement       0.09      0.07      0.08        15\n",
      "disappointment       0.00      0.00      0.00         3\n",
      "   realization       0.00      0.00      0.00         3\n",
      "    admiration       0.09      0.14      0.11         7\n",
      "     annoyance       0.00      0.00      0.00         3\n",
      "     confusion       0.00      0.00      0.00         4\n",
      "      optimism       0.33      0.11      0.17         9\n",
      "    excitement       0.00      0.00      0.00         5\n",
      "        caring       0.00      0.00      0.00         2\n",
      "       remorse       0.00      0.00      0.00         3\n",
      "           joy       0.00      0.00      0.00         2\n",
      "      approval       0.40      0.89      0.55         9\n",
      " embarrassment       0.00      0.00      0.00         4\n",
      "      surprise       0.00      0.00      0.00         6\n",
      "     curiosity       0.00      0.00      0.00         1\n",
      "         anger       0.46      0.78      0.58        65\n",
      "         grief       0.00      0.00      0.00         6\n",
      "       disgust       0.00      0.00      0.00         1\n",
      "         pride       0.00      0.00      0.00         6\n",
      "        desire       0.00      0.00      0.00         1\n",
      "        relief       0.00      0.00      0.00         2\n",
      "          fear       1.00      0.17      0.29         6\n",
      "   nervousness       0.00      0.00      0.00         6\n",
      "\n",
      "      accuracy                           0.36       202\n",
      "     macro avg       0.12      0.11      0.09       202\n",
      "  weighted avg       0.25      0.36      0.27       202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/jupyter/conda/envs/jupyter/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "/software/jupyter/conda/envs/jupyter/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "/software/jupyter/conda/envs/jupyter/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "target_names_0 = clustered_df.level0.unique().tolist()\n",
    "print(classification_report(test_data_0.level0, test_data_0.label_y, target_names=target_names_0))\n",
    "# level0 -> gold standard , label -> prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_y\n",
       "neutral        0.534314\n",
       "admiration     0.174510\n",
       "gratitude      0.091176\n",
       "approval       0.059804\n",
       "curiosity      0.038235\n",
       "disapproval    0.024510\n",
       "anger          0.024510\n",
       "amusement      0.019608\n",
       "annoyance      0.015686\n",
       "love           0.005882\n",
       "sadness        0.004902\n",
       "caring         0.003922\n",
       "optimism       0.001961\n",
       "disgust        0.000980\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Classification/Viz\n",
    "\n",
    "final_0 = data_classifies_0.copy()\n",
    "final_0['label_y'].value_counts()/final_0['label_y'].value_counts().sum() # ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT for level 1 -> 17 + 1 emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>level0</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47072</th>\n",
       "      <td>and [NAME] got blessed with a LocationBot cat fact?! There is no justice in the world...</td>\n",
       "      <td>eefk2mt</td>\n",
       "      <td>themaskedserpent</td>\n",
       "      <td>bestoflegaladvice</td>\n",
       "      <td>2</td>\n",
       "      <td>sadness</td>\n",
       "      <td>dis_sad</td>\n",
       "      <td>dis_sad_gri</td>\n",
       "      <td>rem_emb_dis_sad_gri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49953</th>\n",
       "      <td>and [NAME] got blessed with a LocationBot cat fact?! There is no justice in the world...</td>\n",
       "      <td>eefk2mt</td>\n",
       "      <td>themaskedserpent</td>\n",
       "      <td>bestoflegaladvice</td>\n",
       "      <td>5</td>\n",
       "      <td>disappointment</td>\n",
       "      <td>dis_sad</td>\n",
       "      <td>dis_sad_gri</td>\n",
       "      <td>rem_emb_dis_sad_gri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text  \\\n",
       "47072  and [NAME] got blessed with a LocationBot cat fact?! There is no justice in the world...   \n",
       "49953  and [NAME] got blessed with a LocationBot cat fact?! There is no justice in the world...   \n",
       "\n",
       "            id            author          subreddit  rater_id          level0  \\\n",
       "47072  eefk2mt  themaskedserpent  bestoflegaladvice         2         sadness   \n",
       "49953  eefk2mt  themaskedserpent  bestoflegaladvice         5  disappointment   \n",
       "\n",
       "        level1       level2               level3  \n",
       "47072  dis_sad  dis_sad_gri  rem_emb_dis_sad_gri  \n",
       "49953  dis_sad  dis_sad_gri  rem_emb_dis_sad_gri  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = None # default value is 50, max would be \"None\"\n",
    "pd.set_option('display.max_rows', 50) # default value is 10, max would be \"None\"\n",
    "\n",
    "dis_sad_example = random.sample(list(clustered_df.id[clustered_df.level1 == \"dis_sad\"]), k=1) # example for annoyance\n",
    "clustered_df.query('id==@dis_sad_example')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral          55298\n",
      "app_rea          15973\n",
      "ang_ann          13544\n",
      "pri_adm          11221\n",
      "cur_con          10823\n",
      "dis_sad           8533\n",
      "gra_rel           7863\n",
      "disapproval       7686\n",
      "exc_joy           7349\n",
      "des_opt           6666\n",
      "amusement         6130\n",
      "love              4957\n",
      "caring            3523\n",
      "surprise          3472\n",
      "disgust           2914\n",
      "fea_ner           2574\n",
      "rem_emb           1510\n",
      "embarrassment     1433\n",
      "grief              351\n",
      "Name: level1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if data set is balanced\n",
    "classCounts_1 = clustered_df.level1.value_counts() \n",
    "print(classCounts_1)\n",
    "# -> not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171820"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfDocuments_1 = len(clustered_df)\n",
    "numberOfDocuments_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1, results_1, tokenized_testing_data_1 = get_bert(clustered_df, \"level1\", bert, models_dir, results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_1 = pd.DataFrame.from_dict(results_1)\n",
    "df_id_1 =  pd.DataFrame(dataset_1[\"id\"])\n",
    "df_id_1 = df_id_1.reset_index()\n",
    "df_results_1[\"id\"] = df_id_1[\"id\"]\n",
    "df_results_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifies_1 = pd.merge(dataset_1, df_results_1, on='id', how='left') # merge classified data with original training data\n",
    "data_classifies_1.to_pickle(results_dir +\"data_classified_level1.pkl\") # save\n",
    "data_classifies_1 # contains goldstandard and cluster of results -> calculate F1, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = data_classifies_1.query(f'id in {tokenized_testing_data_1[\"id\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names_1 = clustered_df.level1.unique().tolist()\n",
    "print(classification_report(test_data_1.level1, test_data_1.label_y, target_names=target_names_1))\n",
    "# level1 -> gold standard , label -> prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Classification/Viz\n",
    "#final = pd.concat([dataset, pd.DataFrame.from_dict(results)],axis=1) # attach classified label to data\n",
    "final_1 = data_classifies_1.copy()\n",
    "final_1['label_y'].value_counts()/final_1['label_y'].value_counts().sum() # ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT for level 2 -> 11 + 1 emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None # default value is 50, max would be \"None\"\n",
    "pd.set_option('display.max_rows', 50) # default value is 10, max would be \"None\"\n",
    "\n",
    "dis_sad_gri_example = random.sample(list(clustered_df.id[clustered_df.level2 == \"dis_sad_gri\"]), k=1) # example for annoyance\n",
    "clustered_df.query('id==@dis_sad_gri_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data set is balanced\n",
    "classCounts_2 = clustered_df.level2.value_counts() \n",
    "print(classCounts_2)\n",
    "# -> not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfDocuments_2 = len(clustered_df)\n",
    "numberOfDocuments_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2, results_2, tokenized_testing_data_2 = get_bert(clustered_df, \"level2\", bert, models_dir, results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_2 = pd.DataFrame.from_dict(results_2)\n",
    "df_id_2 =  pd.DataFrame(dataset_2[\"id\"])\n",
    "df_id_2 = df_id_2.reset_index()\n",
    "df_results_2[\"id\"] = df_id_2[\"id\"]\n",
    "df_results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifies_2 = pd.merge(dataset_2, df_results_2, on='id', how='left')\n",
    "data_classifies_2.to_pickle(results_dir +\"data_classified_level2.pkl\")  \n",
    "data_classifies_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2 = data_classifies_2.query(f'id in {tokenized_testing_data_2[\"id\"]}')\n",
    "# tokenized_testing_data: daten der Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names_2 = clustered_df.level2.unique().tolist()\n",
    "print(classification_report(test_data_2.level2, test_data_2.label_y, target_names=target_names_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Classification/Viz\n",
    "\n",
    "final_2 = data_classifies_2.copy()\n",
    "final_2['label_y'].value_counts()/final_2['label_y'].value_counts().sum() # ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT for level 3 -> 7 + 1 emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None # default value is 50, max would be \"None\"\n",
    "pd.set_option('display.max_rows', 50) # default value is 10, max would be \"None\"\n",
    "\n",
    "rem_emb_dis_sad_gri_example = random.sample(list(clustered_df.id[plutchik_df.plutchik == \"rem_emb_dis_sad_gri\"]), k=1) # example for annoyance\n",
    "plutchik_df.query('id==@rem_emb_dis_sad_gri_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data set is balanced\n",
    "classCounts_3 = clustered_df.level3.value_counts() \n",
    "print(classCounts_3)\n",
    "# -> not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfDocuments_3 = len(clustered_df)\n",
    "numberOfDocuments_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3, results_3, tokenized_testing_data_3 = get_bert(clustered_df, \"level3\", bert, models_dir, results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_3 = pd.DataFrame.from_dict(results_3)\n",
    "df_id_3 =  pd.DataFrame(dataset_3[\"id\"])\n",
    "df_id_3 = df_id_3.reset_index()\n",
    "df_results_3[\"id\"] = df_id_3[\"id\"]\n",
    "df_results_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifies_3 = pd.merge(dataset_3, df_results_3, on='id', how='left')\n",
    "data_classifies_3.to_pickle(results_dir +\"data_classified_level3.pkl\")  \n",
    "data_classifies_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_3 = data_classifies_3.query(f'id in {tokenized_testing_data_3[\"id\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names_3 = clustered_df.level3.unique().tolist()\n",
    "print(classification_report(test_data_3.level0, test_data_3.label_y, target_names=target_names_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Classification/Viz\n",
    "\n",
    "final_3 = data_classifies_3.copy()\n",
    "final_3['label_y'].value_counts()/final_3['label_y'].value_counts().sum() # ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT for plutchik -> 14 + 1 emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None # default value is 50, max would be \"None\"\n",
    "pd.set_option('display.max_rows', 50) # default value is 10, max would be \"None\"\n",
    "\n",
    "grief_example = random.sample(list(clustered_df.id[clustered_df.plutchik == \"grief\"]), k=1) # example for annoyance\n",
    "clustered_df.query('id==@grief_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data set is balanced\n",
    "classCounts_p = clustered_df.plutchik.value_counts() \n",
    "print(classCounts_p)\n",
    "# -> not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfDocuments_p = len(clustered_df)\n",
    "numberOfDocuments_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_p, results_p, tokenized_testing_data_p = get_bert(clustered_df, \"plutchik\", bert, models_dir, results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_p = pd.DataFrame.from_dict(results_p)\n",
    "df_id_p =  pd.DataFrame(dataset_p[\"id\"])\n",
    "df_id_p = df_id_p.reset_index()\n",
    "df_results_p[\"id\"] = df_id_p[\"id\"]\n",
    "df_results_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifies_p = pd.merge(dataset_p, df_results_p, on='id', how='left')\n",
    "data_classifies_p.to_pickle(results_dir +\"data_classified_plutchik.pkl\")  \n",
    "data_classifies_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_p = data_classifies_p.query(f'id in {tokenized_testing_data_p[\"id\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names_p = clustered_df.plutchik.unique().tolist()\n",
    "print(classification_report(test_data_p.plutchik, test_data_p.label_y, target_names=target_names_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Classification/Viz\n",
    "\n",
    "final_p = data_classifies_p.copy()\n",
    "final_p['label_y'].value_counts()/final_p['label_y'].value_counts().sum() # ratio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
