{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Text Classification for Emotions using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets huggingface_hub ipywidgets evaluate 'transformers[torch]' torch xformers plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# We need the sys package to load modules from another directory:\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from preprocessing.preprocessors import *\n",
    "from preprocessing.bert_func import *\n",
    "\n",
    "import random\n",
    "import evaluate\n",
    "\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "from plotnine import ggplot, aes, geom_tile, coord_flip,theme,geom_line,labs,element_text\n",
    "from plotnine import scale_x_discrete,geom_vline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 171820 row and 33 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Right? Considering it’s such an important docu...</td>\n",
       "      <td>eespn2i</td>\n",
       "      <td>ImperialBoss</td>\n",
       "      <td>TrueReddit</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211219</th>\n",
       "      <td>Well, I'm glad you're out of all that now. How...</td>\n",
       "      <td>ed89acy</td>\n",
       "      <td>pompompompi</td>\n",
       "      <td>raisedbynarcissists</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>Everyone likes [NAME].</td>\n",
       "      <td>ee6pagw</td>\n",
       "      <td>Senshado</td>\n",
       "      <td>heroesofthestorm</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>Well when you’ve imported about a gazillion of...</td>\n",
       "      <td>ef28nod</td>\n",
       "      <td>5inchloser</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>ee8hse1</td>\n",
       "      <td>springt1me</td>\n",
       "      <td>shittyfoodporn</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here...</td>\n",
       "      <td>edrhoxh</td>\n",
       "      <td>enamedata</td>\n",
       "      <td>medicine</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171820 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       id  \\\n",
       "0                                         That game hurt.  eew5j0j   \n",
       "2          You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "3                                      Man I love reddit.  eeibobj   \n",
       "4       [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "5       Right? Considering it’s such an important docu...  eespn2i   \n",
       "...                                                   ...      ...   \n",
       "211219  Well, I'm glad you're out of all that now. How...  ed89acy   \n",
       "211220                             Everyone likes [NAME].  ee6pagw   \n",
       "211221  Well when you’ve imported about a gazillion of...  ef28nod   \n",
       "211222                                 That looks amazing  ee8hse1   \n",
       "211223  The FDA has plenty to criticize. But like here...  edrhoxh   \n",
       "\n",
       "                     author            subreddit  rater_id  admiration  \\\n",
       "0                     Brdd9                  nrl         1           0   \n",
       "2                  Labalool          confessions        37           0   \n",
       "3             MrsRobertshaw             facepalm        18           0   \n",
       "4       American_Fascist713  starwarsspeculation         2           0   \n",
       "5              ImperialBoss           TrueReddit        61           0   \n",
       "...                     ...                  ...       ...         ...   \n",
       "211219          pompompompi  raisedbynarcissists         2           0   \n",
       "211220             Senshado     heroesofthestorm        16           0   \n",
       "211221           5inchloser          nottheonion        15           0   \n",
       "211222           springt1me       shittyfoodporn        70           1   \n",
       "211223            enamedata             medicine         4           0   \n",
       "\n",
       "        amusement  anger  annoyance  approval  ...  love  nervousness  \\\n",
       "0               0      0          0         0  ...     0            0   \n",
       "2               0      0          0         0  ...     0            0   \n",
       "3               0      0          0         0  ...     1            0   \n",
       "4               0      0          0         0  ...     0            0   \n",
       "5               0      0          0         0  ...     0            0   \n",
       "...           ...    ...        ...       ...  ...   ...          ...   \n",
       "211219          0      0          0         0  ...     0            0   \n",
       "211220          0      0          0         0  ...     1            0   \n",
       "211221          0      0          0         0  ...     0            0   \n",
       "211222          0      0          0         0  ...     0            0   \n",
       "211223          0      1          0         0  ...     0            0   \n",
       "\n",
       "        optimism  pride  realization  relief  remorse  sadness  surprise  \\\n",
       "0              0      0            0       0        0        1         0   \n",
       "2              0      0            0       0        0        0         0   \n",
       "3              0      0            0       0        0        0         0   \n",
       "4              0      0            0       0        0        0         0   \n",
       "5              0      0            0       0        0        0         0   \n",
       "...          ...    ...          ...     ...      ...      ...       ...   \n",
       "211219         0      0            0       0        0        0         0   \n",
       "211220         0      0            0       0        0        0         0   \n",
       "211221         0      0            0       0        0        0         0   \n",
       "211222         0      0            0       0        0        0         0   \n",
       "211223         0      0            0       0        0        0         0   \n",
       "\n",
       "        neutral  \n",
       "0             0  \n",
       "2             1  \n",
       "3             0  \n",
       "4             1  \n",
       "5             0  \n",
       "...         ...  \n",
       "211219        0  \n",
       "211220        0  \n",
       "211221        0  \n",
       "211222        0  \n",
       "211223        0  \n",
       "\n",
       "[171820 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/GoEmotions.csv\")\n",
    "df_clean = clean_df(df)\n",
    "r, c = df_clean.shape\n",
    "print(f\"The data has {r} row and {c} columns\")\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 171820 row and 9 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>level0</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>dis_sad</td>\n",
       "      <td>dis_sad_gri</td>\n",
       "      <td>rem_emb_dis_sad_gri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>37</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>18</td>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "      <td>exc_joy_lov</td>\n",
       "      <td>amu_exc_joy_lov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Right? Considering it’s such an important docu...</td>\n",
       "      <td>eespn2i</td>\n",
       "      <td>ImperialBoss</td>\n",
       "      <td>TrueReddit</td>\n",
       "      <td>61</td>\n",
       "      <td>gratitude</td>\n",
       "      <td>gra_rel</td>\n",
       "      <td>pri_adm_gra_rel</td>\n",
       "      <td>pri_adm_gra_rel_app_rea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211219</th>\n",
       "      <td>Well, I'm glad you're out of all that now. How...</td>\n",
       "      <td>ed89acy</td>\n",
       "      <td>pompompompi</td>\n",
       "      <td>raisedbynarcissists</td>\n",
       "      <td>2</td>\n",
       "      <td>joy</td>\n",
       "      <td>exc_joy</td>\n",
       "      <td>exc_joy_lov</td>\n",
       "      <td>amu_exc_joy_lov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>Everyone likes [NAME].</td>\n",
       "      <td>ee6pagw</td>\n",
       "      <td>Senshado</td>\n",
       "      <td>heroesofthestorm</td>\n",
       "      <td>16</td>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "      <td>exc_joy_lov</td>\n",
       "      <td>amu_exc_joy_lov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>Well when you’ve imported about a gazillion of...</td>\n",
       "      <td>ef28nod</td>\n",
       "      <td>5inchloser</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>15</td>\n",
       "      <td>caring</td>\n",
       "      <td>caring</td>\n",
       "      <td>des_opt_car</td>\n",
       "      <td>des_opt_car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>ee8hse1</td>\n",
       "      <td>springt1me</td>\n",
       "      <td>shittyfoodporn</td>\n",
       "      <td>70</td>\n",
       "      <td>admiration</td>\n",
       "      <td>pri_adm</td>\n",
       "      <td>pri_adm_gra_rel</td>\n",
       "      <td>pri_adm_gra_rel_app_rea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here...</td>\n",
       "      <td>edrhoxh</td>\n",
       "      <td>enamedata</td>\n",
       "      <td>medicine</td>\n",
       "      <td>4</td>\n",
       "      <td>anger</td>\n",
       "      <td>ang_ann</td>\n",
       "      <td>dis_ang_ann</td>\n",
       "      <td>dis_ang_ann_dis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171820 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       id  \\\n",
       "0                                         That game hurt.  eew5j0j   \n",
       "2          You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "3                                      Man I love reddit.  eeibobj   \n",
       "4       [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "5       Right? Considering it’s such an important docu...  eespn2i   \n",
       "...                                                   ...      ...   \n",
       "211219  Well, I'm glad you're out of all that now. How...  ed89acy   \n",
       "211220                             Everyone likes [NAME].  ee6pagw   \n",
       "211221  Well when you’ve imported about a gazillion of...  ef28nod   \n",
       "211222                                 That looks amazing  ee8hse1   \n",
       "211223  The FDA has plenty to criticize. But like here...  edrhoxh   \n",
       "\n",
       "                     author            subreddit  rater_id      level0  \\\n",
       "0                     Brdd9                  nrl         1     sadness   \n",
       "2                  Labalool          confessions        37     neutral   \n",
       "3             MrsRobertshaw             facepalm        18        love   \n",
       "4       American_Fascist713  starwarsspeculation         2     neutral   \n",
       "5              ImperialBoss           TrueReddit        61   gratitude   \n",
       "...                     ...                  ...       ...         ...   \n",
       "211219          pompompompi  raisedbynarcissists         2         joy   \n",
       "211220             Senshado     heroesofthestorm        16        love   \n",
       "211221           5inchloser          nottheonion        15      caring   \n",
       "211222           springt1me       shittyfoodporn        70  admiration   \n",
       "211223            enamedata             medicine         4       anger   \n",
       "\n",
       "         level1           level2                   level3  \n",
       "0       dis_sad      dis_sad_gri      rem_emb_dis_sad_gri  \n",
       "2       neutral          neutral                  neutral  \n",
       "3          love      exc_joy_lov          amu_exc_joy_lov  \n",
       "4       neutral          neutral                  neutral  \n",
       "5       gra_rel  pri_adm_gra_rel  pri_adm_gra_rel_app_rea  \n",
       "...         ...              ...                      ...  \n",
       "211219  exc_joy      exc_joy_lov          amu_exc_joy_lov  \n",
       "211220     love      exc_joy_lov          amu_exc_joy_lov  \n",
       "211221   caring      des_opt_car              des_opt_car  \n",
       "211222  pri_adm  pri_adm_gra_rel  pri_adm_gra_rel_app_rea  \n",
       "211223  ang_ann      dis_ang_ann          dis_ang_ann_dis  \n",
       "\n",
       "[171820 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_df = create_clustered_df(df_clean)\n",
    "\n",
    "r, c = clustered_df.shape\n",
    "print(f\"The data has {r} row and {c} columns\")\n",
    "clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 171820 row and 7 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>level0</th>\n",
       "      <th>plutchik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>betrübt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>37</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>18</td>\n",
       "      <td>love</td>\n",
       "      <td>verliebt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Right? Considering it’s such an important docu...</td>\n",
       "      <td>eespn2i</td>\n",
       "      <td>ImperialBoss</td>\n",
       "      <td>TrueReddit</td>\n",
       "      <td>61</td>\n",
       "      <td>gratitude</td>\n",
       "      <td>ehrfürchtig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211219</th>\n",
       "      <td>Well, I'm glad you're out of all that now. How...</td>\n",
       "      <td>ed89acy</td>\n",
       "      <td>pompompompi</td>\n",
       "      <td>raisedbynarcissists</td>\n",
       "      <td>2</td>\n",
       "      <td>joy</td>\n",
       "      <td>begeistert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>Everyone likes [NAME].</td>\n",
       "      <td>ee6pagw</td>\n",
       "      <td>Senshado</td>\n",
       "      <td>heroesofthestorm</td>\n",
       "      <td>16</td>\n",
       "      <td>love</td>\n",
       "      <td>verliebt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>Well when you’ve imported about a gazillion of...</td>\n",
       "      <td>ef28nod</td>\n",
       "      <td>5inchloser</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>15</td>\n",
       "      <td>caring</td>\n",
       "      <td>bewundernd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>ee8hse1</td>\n",
       "      <td>springt1me</td>\n",
       "      <td>shittyfoodporn</td>\n",
       "      <td>70</td>\n",
       "      <td>admiration</td>\n",
       "      <td>bewundernd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here...</td>\n",
       "      <td>edrhoxh</td>\n",
       "      <td>enamedata</td>\n",
       "      <td>medicine</td>\n",
       "      <td>4</td>\n",
       "      <td>anger</td>\n",
       "      <td>wütend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171820 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       id  \\\n",
       "0                                         That game hurt.  eew5j0j   \n",
       "2          You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "3                                      Man I love reddit.  eeibobj   \n",
       "4       [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "5       Right? Considering it’s such an important docu...  eespn2i   \n",
       "...                                                   ...      ...   \n",
       "211219  Well, I'm glad you're out of all that now. How...  ed89acy   \n",
       "211220                             Everyone likes [NAME].  ee6pagw   \n",
       "211221  Well when you’ve imported about a gazillion of...  ef28nod   \n",
       "211222                                 That looks amazing  ee8hse1   \n",
       "211223  The FDA has plenty to criticize. But like here...  edrhoxh   \n",
       "\n",
       "                     author            subreddit  rater_id      level0  \\\n",
       "0                     Brdd9                  nrl         1     sadness   \n",
       "2                  Labalool          confessions        37     neutral   \n",
       "3             MrsRobertshaw             facepalm        18        love   \n",
       "4       American_Fascist713  starwarsspeculation         2     neutral   \n",
       "5              ImperialBoss           TrueReddit        61   gratitude   \n",
       "...                     ...                  ...       ...         ...   \n",
       "211219          pompompompi  raisedbynarcissists         2         joy   \n",
       "211220             Senshado     heroesofthestorm        16        love   \n",
       "211221           5inchloser          nottheonion        15      caring   \n",
       "211222           springt1me       shittyfoodporn        70  admiration   \n",
       "211223            enamedata             medicine         4       anger   \n",
       "\n",
       "           plutchik  \n",
       "0           betrübt  \n",
       "2           neutral  \n",
       "3          verliebt  \n",
       "4           neutral  \n",
       "5       ehrfürchtig  \n",
       "...             ...  \n",
       "211219   begeistert  \n",
       "211220     verliebt  \n",
       "211221   bewundernd  \n",
       "211222   bewundernd  \n",
       "211223       wütend  \n",
       "\n",
       "[171820 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plutchik_df = create_plutchik_df(df_clean)\n",
    "\n",
    "r, c = plutchik_df.shape\n",
    "print(f\"The data has {r} row and {c} columns\")\n",
    "plutchik_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Classifier\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTILBERT for level 0 -> 27 + 1 emotions\n",
    "following: https://huggingface.co/docs/transformers/tasks/sequence_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None # default value is 50, max would be \"None\"\n",
    "pd.set_option('display.max_rows', 50) # default value is 10, max would be \"None\"\n",
    "\n",
    "annoyance_example = random.sample(list(clustered_df.id[clustered_df.level0 == \"annoyance\"]), k=1) # example for annoyance\n",
    "clustered_df.query('id==@annoyance_example')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desire_example = random.sample(list(clustered_df.id[clustered_df.level0 == \"desire\"]), k=1) # example for desire\n",
    "clustered_df.query('id==@desire_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral           55298\n",
      "approval          11259\n",
      "admiration        10531\n",
      "annoyance          8342\n",
      "disapproval        7686\n",
      "gratitude          7075\n",
      "amusement          6130\n",
      "curiosity          5885\n",
      "anger              5202\n",
      "love               4957\n",
      "confusion          4938\n",
      "realization        4714\n",
      "disappointment     4706\n",
      "optimism           4519\n",
      "joy                4329\n",
      "sadness            3827\n",
      "caring             3523\n",
      "surprise           3472\n",
      "excitement         3020\n",
      "disgust            2914\n",
      "desire             2147\n",
      "fear               1778\n",
      "remorse            1510\n",
      "embarrassment      1433\n",
      "nervousness         796\n",
      "relief              788\n",
      "pride               690\n",
      "grief               351\n",
      "Name: level0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if data set is balanced\n",
    "classCounts_0 = clustered_df.level0.value_counts() \n",
    "print(classCounts_0)\n",
    "# -> not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171820"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfDocuments_0 = len(clustered_df)\n",
    "numberOfDocuments_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_0, results_0, tokenized_testing_data_0 = get_bert(clustered_df, \"level0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.176830</td>\n",
       "      <td>eez4phj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.703029</td>\n",
       "      <td>eeejsh7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.079363</td>\n",
       "      <td>ed8auqx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.420149</td>\n",
       "      <td>ee103qd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.331734</td>\n",
       "      <td>efaudck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>admiration</td>\n",
       "      <td>0.081957</td>\n",
       "      <td>eetak09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>approval</td>\n",
       "      <td>0.110026</td>\n",
       "      <td>edlin87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.214870</td>\n",
       "      <td>ed23fr7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.735096</td>\n",
       "      <td>eeb063d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.362268</td>\n",
       "      <td>eeskl7s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label     score       id\n",
       "0       neutral  0.176830  eez4phj\n",
       "1       neutral  0.703029  eeejsh7\n",
       "2       neutral  0.079363  ed8auqx\n",
       "3       neutral  0.420149  ee103qd\n",
       "4       neutral  0.331734  efaudck\n",
       "..          ...       ...      ...\n",
       "995  admiration  0.081957  eetak09\n",
       "996    approval  0.110026  edlin87\n",
       "997     neutral  0.214870  ed23fr7\n",
       "998     neutral  0.735096  eeb063d\n",
       "999     neutral  0.362268  eeskl7s\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_0 = pd.DataFrame.from_dict(results_0)\n",
    "df_id_0 =  pd.DataFrame(dataset_0[\"id\"])\n",
    "df_id_0 = df_id_0.reset_index()\n",
    "df_results_0[\"id\"] = df_id_0[\"id\"]\n",
    "df_results_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifies_0 = pd.merge(dataset_0, df_results_0, on='id', how='left') # merge classified data with original training data\n",
    "data_classifies_0.to_pickle(\"../results/distilbert/data_classified_level0.pkl\")  \n",
    "data_classifies_0 # contain sgoldstandard and cluster of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_0 = data_classifies_0.query(f'id in {tokenized_testing_data_0[\"id\"]}')\n",
    "# tokenized_testing_data: daten der Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "       sadness       0.25      0.75      0.38        12\n",
      "          love       0.00      0.00      0.00         6\n",
      "     gratitude       0.00      0.00      0.00         7\n",
      "   disapproval       0.50      0.12      0.20         8\n",
      "     amusement       0.09      0.07      0.08        15\n",
      "disappointment       0.00      0.00      0.00         3\n",
      "   realization       0.00      0.00      0.00         3\n",
      "    admiration       0.09      0.14      0.11         7\n",
      "     annoyance       0.00      0.00      0.00         3\n",
      "     confusion       0.00      0.00      0.00         4\n",
      "      optimism       0.33      0.11      0.17         9\n",
      "    excitement       0.00      0.00      0.00         5\n",
      "        caring       0.00      0.00      0.00         2\n",
      "       remorse       0.00      0.00      0.00         3\n",
      "           joy       0.00      0.00      0.00         2\n",
      "      approval       0.40      0.89      0.55         9\n",
      " embarrassment       0.00      0.00      0.00         4\n",
      "      surprise       0.00      0.00      0.00         6\n",
      "     curiosity       0.00      0.00      0.00         1\n",
      "         anger       0.46      0.78      0.58        65\n",
      "         grief       0.00      0.00      0.00         6\n",
      "       disgust       0.00      0.00      0.00         1\n",
      "         pride       0.00      0.00      0.00         6\n",
      "        desire       0.00      0.00      0.00         1\n",
      "        relief       0.00      0.00      0.00         2\n",
      "          fear       1.00      0.17      0.29         6\n",
      "   nervousness       0.00      0.00      0.00         6\n",
      "\n",
      "      accuracy                           0.36       202\n",
      "     macro avg       0.12      0.11      0.09       202\n",
      "  weighted avg       0.25      0.36      0.27       202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/jupyter/conda/envs/jupyter/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "/software/jupyter/conda/envs/jupyter/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "/software/jupyter/conda/envs/jupyter/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "target_names_0 = clustered_df.level0.unique().tolist()\n",
    "print(classification_report(test_data_0.level0, test_data_0.label_y, target_names=target_names_0))\n",
    "# level0 -> gold standard , label -> prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_y\n",
       "neutral        0.534314\n",
       "admiration     0.174510\n",
       "gratitude      0.091176\n",
       "approval       0.059804\n",
       "curiosity      0.038235\n",
       "disapproval    0.024510\n",
       "anger          0.024510\n",
       "amusement      0.019608\n",
       "annoyance      0.015686\n",
       "love           0.005882\n",
       "sadness        0.004902\n",
       "caring         0.003922\n",
       "optimism       0.001961\n",
       "disgust        0.000980\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Classification/Viz\n",
    "\n",
    "final_0 = data_classifies_0.copy()\n",
    "final_0['label_y'].value_counts()/final_0['label_y'].value_counts().sum() # ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTILBERT for level 1 -> 17 + 1 emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>level0</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47072</th>\n",
       "      <td>and [NAME] got blessed with a LocationBot cat fact?! There is no justice in the world...</td>\n",
       "      <td>eefk2mt</td>\n",
       "      <td>themaskedserpent</td>\n",
       "      <td>bestoflegaladvice</td>\n",
       "      <td>2</td>\n",
       "      <td>sadness</td>\n",
       "      <td>dis_sad</td>\n",
       "      <td>dis_sad_gri</td>\n",
       "      <td>rem_emb_dis_sad_gri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49953</th>\n",
       "      <td>and [NAME] got blessed with a LocationBot cat fact?! There is no justice in the world...</td>\n",
       "      <td>eefk2mt</td>\n",
       "      <td>themaskedserpent</td>\n",
       "      <td>bestoflegaladvice</td>\n",
       "      <td>5</td>\n",
       "      <td>disappointment</td>\n",
       "      <td>dis_sad</td>\n",
       "      <td>dis_sad_gri</td>\n",
       "      <td>rem_emb_dis_sad_gri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text  \\\n",
       "47072  and [NAME] got blessed with a LocationBot cat fact?! There is no justice in the world...   \n",
       "49953  and [NAME] got blessed with a LocationBot cat fact?! There is no justice in the world...   \n",
       "\n",
       "            id            author          subreddit  rater_id          level0  \\\n",
       "47072  eefk2mt  themaskedserpent  bestoflegaladvice         2         sadness   \n",
       "49953  eefk2mt  themaskedserpent  bestoflegaladvice         5  disappointment   \n",
       "\n",
       "        level1       level2               level3  \n",
       "47072  dis_sad  dis_sad_gri  rem_emb_dis_sad_gri  \n",
       "49953  dis_sad  dis_sad_gri  rem_emb_dis_sad_gri  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = None # default value is 50, max would be \"None\"\n",
    "pd.set_option('display.max_rows', 50) # default value is 10, max would be \"None\"\n",
    "\n",
    "dis_sad_example = random.sample(list(clustered_df.id[clustered_df.level1 == \"dis_sad\"]), k=1) # example for annoyance\n",
    "clustered_df.query('id==@dis_sad_example')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral          55298\n",
      "app_rea          15973\n",
      "ang_ann          13544\n",
      "pri_adm          11221\n",
      "cur_con          10823\n",
      "dis_sad           8533\n",
      "gra_rel           7863\n",
      "disapproval       7686\n",
      "exc_joy           7349\n",
      "des_opt           6666\n",
      "amusement         6130\n",
      "love              4957\n",
      "caring            3523\n",
      "surprise          3472\n",
      "disgust           2914\n",
      "fea_ner           2574\n",
      "rem_emb           1510\n",
      "embarrassment     1433\n",
      "grief              351\n",
      "Name: level1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if data set is balanced\n",
    "classCounts_1 = clustered_df.level1.value_counts() \n",
    "print(classCounts_1)\n",
    "# -> not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171820"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfDocuments_1 = len(clustered_df)\n",
    "numberOfDocuments_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1, results_1, tokenized_testing_data_1 = get_bert(clustered_df, \"level1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_1 = pd.DataFrame.from_dict(results_1)\n",
    "df_id_1 =  pd.DataFrame(dataset_1[\"id\"])\n",
    "df_id_1 = df_id_1.reset_index()\n",
    "df_results_1[\"id\"] = df_id_1[\"id\"]\n",
    "df_results_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifies_1 = pd.merge(dataset_1, df_results_1, on='id', how='left') # merge classified data with original training data\n",
    "data_classifies_1.to_pickle(\"../results/distilbert/data_classified_level1.pkl\") # save\n",
    "data_classifies_1 # contains goldstandard and cluster of results -> calculate F1, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = data_classifies_1.query(f'id in {tokenized_testing_data_1[\"id\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names_1 = clustered_df.level1.unique().tolist()\n",
    "print(classification_report(test_data_1.level1, test_data_1.label_y, target_names=target_names_1))\n",
    "# level1 -> gold standard , label -> prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Classification/Viz\n",
    "#final = pd.concat([dataset, pd.DataFrame.from_dict(results)],axis=1) # attach classified label to data\n",
    "final_1 = data_classifies_1.copy()\n",
    "final_1['label_y'].value_counts()/final_1['label_y'].value_counts().sum() # ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTILBERT for level 2 -> 12 + 1 emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None # default value is 50, max would be \"None\"\n",
    "pd.set_option('display.max_rows', 50) # default value is 10, max would be \"None\"\n",
    "\n",
    "dis_sad_gri_example = random.sample(list(clustered_df.id[clustered_df.level2 == \"dis_sad_gri\"]), k=1) # example for annoyance\n",
    "clustered_df.query('id==@dis_sad_gri_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data set is balanced\n",
    "classCounts_2 = clustered_df.level2.value_counts() \n",
    "print(classCounts_2)\n",
    "# -> not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfDocuments_2 = len(clustered_df)\n",
    "numberOfDocuments_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2, results_2, tokenized_testing_data_2 = get_bert(clustered_df, \"level2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_2 = pd.DataFrame.from_dict(results_2)\n",
    "df_id_2 =  pd.DataFrame(dataset_2[\"id\"])\n",
    "df_id_2 = df_id_2.reset_index()\n",
    "df_results_2[\"id\"] = df_id_2[\"id\"]\n",
    "df_results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifies_2 = pd.merge(dataset_2, df_results_2, on='id', how='left')\n",
    "data_classifies_2.to_pickle(\"../results/destilbert/data_classified_level2.pkl\")  \n",
    "data_classifies_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2 = data_classifies_2.query(f'id in {tokenized_testing_data_2[\"id\"]}')\n",
    "# tokenized_testing_data: daten der Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names_2 = clustered_df.level2.unique().tolist()\n",
    "print(classification_report(test_data_2.level2, test_data_2.label_y, target_names=target_names_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Classification/Viz\n",
    "\n",
    "final_2 = data_classifies_2.copy()\n",
    "final_2['label_y'].value_counts()/final_2['label_y'].value_counts().sum() # ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTILBERT for level 3 -> 9 emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None # default value is 50, max would be \"None\"\n",
    "pd.set_option('display.max_rows', 50) # default value is 10, max would be \"None\"\n",
    "\n",
    "rem_emb_dis_sad_gri_example = random.sample(list(clustered_df.id[plutchik_df.plutchik == \"rem_emb_dis_sad_gri\"]), k=1) # example for annoyance\n",
    "plutchik_df.query('id==@rem_emb_dis_sad_gri_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data set is balanced\n",
    "classCounts_3 = clustered_df.level3.value_counts() \n",
    "print(classCounts_3)\n",
    "# -> not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfDocuments_3 = len(clustered_df)\n",
    "numberOfDocuments_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3, results_3, tokenized_testing_data_3 = get_bert(clustered_df, \"level3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_3 = pd.DataFrame.from_dict(results_3)\n",
    "df_id_3 =  pd.DataFrame(dataset_3[\"id\"])\n",
    "df_id_3 = df_id_3.reset_index()\n",
    "df_results_3[\"id\"] = df_id_3[\"id\"]\n",
    "df_results_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifies_3 = pd.merge(dataset_3, df_results_3, on='id', how='left')\n",
    "data_classifies_3.to_pickle(\"../results/destilbert/data_classified_level3.pkl\")  \n",
    "data_classifies_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_3 = data_classifies_3.query(f'id in {tokenized_testing_data_3[\"id\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names_3 = clustered_df.level3.unique().tolist()\n",
    "print(classification_report(test_data_3.level0, test_data_3.label_y, target_names=target_names_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Classification/Viz\n",
    "\n",
    "final_3 = data_classifies_3.copy()\n",
    "final_3['label_y'].value_counts()/final_3['label_y'].value_counts().sum() # ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTILBERT for plutchik -> 16 emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None # default value is 50, max would be \"None\"\n",
    "pd.set_option('display.max_rows', 50) # default value is 10, max would be \"None\"\n",
    "\n",
    "betrübt_example = random.sample(list(clustered_df.id[plutchik_df.level3 == \"betrübt\"]), k=1) # example for annoyance\n",
    "plutchik_df.query('id==@betrübt_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data set is balanced\n",
    "classCounts_p = plutchik_df.plutchik.value_counts() \n",
    "print(classCounts_p)\n",
    "# -> not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfDocuments_p = len(plutchik_df)\n",
    "numberOfDocuments_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_p, results_p, tokenized_testing_data_p = get_bert(plutchik_df, \"plutchik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_p = pd.DataFrame.from_dict(results_p)\n",
    "df_id_p =  pd.DataFrame(dataset_p[\"id\"])\n",
    "df_id_p = df_id_p.reset_index()\n",
    "df_results_p[\"id\"] = df_id_p[\"id\"]\n",
    "df_results_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifies_p = pd.merge(dataset_p, df_results_p, on='id', how='left')\n",
    "data_classifies_p.to_pickle(\"../results/destilbert/data_classified_plutchik.pkl\")  \n",
    "data_classifies_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_p = data_classifies_p.query(f'id in {tokenized_testing_data_3[\"id\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names_p = plutchik_df.plutchik.unique().tolist()\n",
    "print(classification_report(test_data_p.plutchik, test_data_p.label_y, target_names=target_names_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Classification/Viz\n",
    "\n",
    "final_p = data_classifies_p.copy()\n",
    "final_p['label_y'].value_counts()/final_p['label_y'].value_counts().sum() # ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
